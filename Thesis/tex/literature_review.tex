\chapter{\chapzerotitle}
\label{chap:literature_review}


\section{Introduction}
The literature review is an essential step of the research process. In addition to increasing the wealth of knowledge in the field, it helps to ensure the relevance of the targeted contributions relative to existing work. In our case, we are interested in the influence of complex environments on \gls*{lidar}-based robot navigation, which is a high-level problem involving several subtopics. We will start our literature review with a general overview of the work on navigation in complex environments and the use of \gls*{lidar} (Section~\ref{sec:literature_general}). Subsequently, in Section~\ref{sec:literature_snow}, we will discuss research related to \gls*{lidar} functioning and the influence of snowfall on data, which is the topic of Chapter~\ref{chap:lidar_snow}. Finally, to contextualize Chapter~\ref{chap:slam}, Section~\ref{sec:literature_slam} will present papers related to feature-based place recognition and navigation in forest environments. 


\section{Overview: Navigation in Complex Environments and \gls*{lidar} Uses}
\label{sec:literature_general}

Start with a navigation definition... Which include stuff like ... Obstacle avoidance/traversability for path planning, localisation and mapping... 
Give some insight for what might be a "complex" environment (there is a gradation from completely controlled, to indoor, to outdoor, to forest etc.)

\subsubsection{Path Planning}
Geolocation, obstacles avoidance / traversability (including ground classification) = path planning

~\cite{Hussein2015}:
Geolocation of ugv in forest (horizontal position) by finding geometric match between a map of observed tree stems using onboard lidar with a map generated from the structure of thee crowns from high resolution aerial orthoimagery of the forest canopy. No need for a priori knowledge of the area surrounding the robot, only input is the geometry of detected tree stems.

\subsubsection{Localisation and Mapping + SLAM}
Start with 2d solutions. (Gmapping), but can't deal with 3D conditions or uneven bearing surface. Hector propose a 2d + imu that slighly handle uneven floor.
State that 2D solutions for slam pretty much meet our needs, they are able to yield precise results in real time\dots

~\cite{Grisetti2007}: Gmapping,
They use a particle filter to solve SLAM (grid map). Each particle carry an individual map. They take into account the movement but also the most recent observations, which decrease uncertainty. They use selective selective resampling to reduce the problem of particle depletion. They do indoor AND outdoor. 

~\cite{Kohlbrecher2011}: Hector mapping,
Focus on search and rescue. Learn map of unknown environments, occupancy grid, low computational resources. Lidar + IMU. Fast approximation of map gradients and multi resolution grids. Pretend they don't need explicit loop closure\dots


Then they start using 3D, this is more applicable to complex environments (remove some assumptions such as even ground).
Quickly explain ICP, can be used for small steps localisation, but converge in minimum and can't be used directly for localisation (for any given input scan)

~\cite{Besl1992}:
Original ICP article

~\cite{Pomerleau2015a}:
A Review of Point Cloud Registration Algorithms for Mobile Robotics\dots

~\cite{Colas2013}:
Article doing path planning in complex environments for search and rescue based on ICP for 3D terrains. 

~\cite{Pomerleau2013}:
This article present an analysis of ICP variants for real world applications. They also propose an open-source icp library that operate in real time.  


\section{\gls*{lidar} Functionning and Snowy Conditions}
\label{sec:literature_snow}

Sensors are the basis of perception required for navigation. 
\begin{itemize}
    \item Lower level lidar article (Sensor characterization, fusion, calibration\dots) 
    \item Literature from our article
\end{itemize}

~\cite{Bosch2001}:
Review usual lidar techniques (pulsed, phase-shift and frequency modulated continuous wave), basics then limitations.


\section{Feature-Based Place Recognition and Forest Environments}
\label{sec:literature_slam}
Place 
\begin{itemize}
    \item Talk about features first (the idea originate from 2D images, list the most popular)
    \item Talk about features-based place recognition in general (camera-based, NDT...)
    \item Talk about tree trunk as features in forest
\end{itemize}

While we will not address this topic specifically, the algorithm used for the place recognition analysis highly depends on the chosen features.  
Bring table about features here if I do. Might want to include the part about tree features discussed in the next section. Put comparative analysis. Tackle DNN.
~\cite{Steder2011a} NARF, ~\cite{Rusu2009} FPFH, ~\cite{Yu2009} ISS, ~\cite{Tombari2010} SHOT, ~\cite{Harris1988} Harris, ~\cite{Lowe2004} SIFT, ~\cite{Bay2006} SURF

~\cite{Filipe2014}:
Comparative evalutation of 3D Keypoint Detectors in RGB-D Obeject dataset. They verify the invariance of the 3D keypoints detectors to rotaions, scales and translation.

~\cite{Magnusson2009}:
This is NDT. First in my knowledge to do loop closure based on 3D laser scans. Address the problems of greater amount of data (3D vs 2D) and the 3D rotation invariance. NDT surface representation to create feature histograms based on the surface orientation and smoothness (this compress data). Rotation invariance via alignment of dominant surface orientations.

~\cite{Song2012}:(might be good to cite original ICP or review from F. Pomerleau)
They proposes a localisation solution in forested environments. They use the largest group of approximately parallel tree trunk features to align successive scans along five dimensions (except z). Optimal transformation determined based on the axes of two tree pairs. Then they align ground by minimizing the differences of points shared in the cells. (they basically do ICP, but they pretend to remove problems such as initial transformation and noisy scene.) (This is high level engineered features, could use this for smooth transition in the text)

~\cite{Iagnemma2012}:
The method used in the previous article to extract tree truck parameters from point cloud. 3 purely geometric steps: First, the raw point clouds are segmented by utilizing the circular shape of trees, and segments are grouped into tree sections based on the principle of spatial proximity. Second, circles and axes are extracted from tree sections which are subject to loss of shape information. Third, by clustering and integrating the tree sections resulted from various space inconsistencies, straight tree trunk landmarks are finally formed for future localization. The experimental results from real forested environments are presented.

~\cite{Mcdaniel2012}:
Article that segment ground and trees that I used at the beginning of my master. (include in the path planning section)

~\cite{Lalonde2006}:
J-F Lalonde article about vegetation classification using eigenvalues/vectors. (include in the path planning section)

~\cite{Wurm2009}:
This paper present a technique that use laser remission values to detect grass like vegetation. They use a self-supervised classification vibration based. (include in the path planning section)

\begin{table}[H]
    \centering
    \begin{tabular}{@{}llll@{}}
        \toprule
        \textbf{Type of data}  & \textbf{Keypoint/descriptor} & \textbf{Name}               & \textbf{Reference} \\
        \hline
        Image                  & Keypoint                     & Harris and Stephens corners & \cite{Harris1988}  \\
        Image                  & Both                         & SIFT                        & \cite{Lowe2004}    \\
        Image                  & Both                         & SURF                        & \cite{Bay2006}     \\
        \gls*{3d}              & Descriptor                   & FPFH                        & \cite{Rusu2009}    \\
        \gls*{3d}              & Both                         & ISS                         & \cite{Yu2009}      \\
        \gls*{3d}              & Descriptor                   & SHOT                        & \cite{Tombari2010} \\
        \gls*{3d}              & Both                         & NARF                        & \cite{Steder2011a} \\
        \bottomrule
    \end{tabular}
    \caption[Examples of popular descriptors and keypoints detectors for images and \gls*{3d} data.]{Examples of popular descriptors and keypoints detectors for images and \gls*{3d} data. Some \gls*{2d} keypoints have been adapted for \gls*{3d} such as Harris and Stephens and SIFT.}
    \label{tab:features_examples}
\end{table}
