\chapter*{Conclusion}
\phantomsection\addcontentsline{toc}{chapter}{Conclusion}

The objective of this document was to analyse the influence of complex environments on different \gls*{lidar}s used in a context of mobile robotics navigation. Because \gls*{lidar}s can effectively retrieve the three-dimensional structure of an environment, they can advantageously be used for several navigation tasks, such as obstacles avoidance, localization and mapping. The information they provide is complementary to that of other sensors such as cameras, which capture information on the appearance of the surrounding scene. Although the literature on mobile robotic navigation is rich, most existing research deal with indoor or structured outdoor environment and dealing with complex environments such as forest or falling snow condition remains a important problem. Analyzing how such complex environments influence the \gls*{lidar}-based navigation can help to develop algorithms that are more robust to changing conditions.

In Chapter~\ref{chap:lidar_snow}, we focused our attention on the impact of falling snow on \gls*{lidar} data. For that matter, we first presented an overview of \gls*{lidar}s functioning, which helped understand what could potentially cause noise in the data. The first issue raised is that when the spot produced by the laser beam is not completely on a single target, a method of inference of the distance must be chosen and may not be suitable for the application. This is generally caused by object edges of small particles. The second issue raised is \gls*{lidar}s acquire data points sequentially, which can lead to a distorted representation of the scene when the environment is dynamic. Consequently, the dynamic nature and small size of snowflakes make snowfall a perfect example of challenging condition for \gls*{lidar} acquisition.

To perform our analysis of the impact of falling snow on \gls*{lidar} acquisition, we collected data from four sensors simultaneously (Velodyne HDL-32E, SICK LMS151, SICK LMS200 and Hokuyo UTM-30LX-EW) during six snowfalls. We then computed the faction of echoes caused by snowflakes
\todo{I'll have to read again to summarize better}

\begin{itemize}
    \item using the fraction of echoes returned/caused by snoflakes, analyse quantitative and spacial differences
    \item show strong variation fraction and distribution between different conditions
    \item older sensor (LMS200) more sensible to snowflake, LMS151, hokuyo last 2 echoes ~ 200-151 and 2nd echoes ~ velodyne
    \item there is a range upon which snowflakes no longer seem to trigger measurement -  around 10 meters
    \item propose a model for lidar in snowfall log-normal
    \item LMS200 most sensitive and peak at 15\% caused by snowflakes others never exceed 1\%
    \item still things to explore... intensities, shielding effect of building == no close range
\end{itemize}

In Chapter~\ref{chap:slam}, we have conducted our analysis at a higher level by comparing the performance of a state-of-the-art \gls*{lidar}-based place recognition algorithm in different environments. There are two main reasons for this choice. Firstly, the ability of a robot to identify previously visited places allows to solve several other navigation problems, such as multi-session-mapping, kidnapped robot and \gls*{slam}. Secondly, the chosen algorithm proved to be successful in indoor and structured outdoor environments, but have not been tested in unstructured environments.

For our comparative analysis, we acquired datasets in two different area of the Laval University campus using the Husky A200 mobile robot. The first area is our model for a structured outdoor environment, similar to those on which the original algorithm was tested. In this location, the ground is mostly flat and the scanned space contains several man-made objects, such as buildings, stairs and lampposts. The second area, representing our unstructured environment, is in a forest where the ground is uneven in some parts. We also used two different sensors for our acquisitions, namely the SICK LMS151 and the Velodyne HDL-32E. We used the resulting Structured-SICK, Unstructured-SICK and Unstructured-Velodyne datasets to evaluate the impact of both the environment and the sensor choice on the place recognition performance.

Before performing the comparative analysis itself, we presented some fundamental concepts required to understand the chosen algorithm. This include features keypoints and descriptors, range images and scans comparison techniques. We then proceed to explain the algorithm itself, which first convert point clouds into range images in order to extract NARF features and then use a mixture of \gls*{bow} and features matching to find possible transformations between two scans. The final output of the algorithm is a score computed from the best possible transformation betweens two scans, and represent the confidence of the system that those scans originate from the same place. 

For our results presentation, we showed the relation between the algorithm output score and the distance separating the input scans. We consider that the closer two scans are from each other, the more likely they are to represent the same place. Therefore, we expected an inverse relation between the score and the distance separating the scans. We also presented the results using binary labels, because practical uses of place recognition generally required pairs of scans to be identified as originating from the same place or not. For that matter, all scans for which the distance between them was below a threshold were considered as belonging to the same place. Similarly, we considered that if the score obtained for a pair of scans was above a threshold, the algorithm labeled the input scans as representing the same place. This labeling also enabled us to identify \gls*{fp} and calculate the recall for different thresholds combinations. As we explained, \gls*{fp} must be avoided during \gls*{slam}, because they create false loop closures, which distort the resulting map. 

The presentation of results as described above enabled us to make our final observations. As expected, we showed a relation of the form $f(x)=1/x$ between the algorithm output score and the distance between two scans. This was true for our three datasets. However, some outliers were observed for the unstructured environment, whereas this was not the case for the structured environment. When using the discretized labels, such outliers can result in \gls*{fp} or, if the score threshold is adjusted to avoid them, reduce significantly the recall. Our last observation is that the score decreases more rapidly as a function of the distance between scans in the unstructured environment than in the structured environment. This means that the algorithm is more sensitive to disturbances and noise in an unstructured environment than in the structured environment. The same observation applies when comparing the sensors, in which case the Velodyne is more sensitive than the SICK.

The goal of this document was to evaluate the influence of complex environments when using \gls*{lidar}s for robot navigation. By characterizing \gls*{lidar}s data acquired during snowfalls and by comparing performances of \gls*{lidar}-based place recognition in forest and in structured outdoor environment, we showed that these environments can impact negatively robot navigation. Based on our observations, future research could focus on finding methods to increase robustness to these conditions, for instance by filtering data. In the case of our place recognition analysis, a better identification of the sources causing the performance loss could also help the development of better algorithms.
