\section{Conclusion}
\label{sec:chap_slam_conclu}

This chapter focused on the impact of the structural level of an environment on the performance of a \gls*{lidar}-based place recognition algorithm. As explained, these algorithms are useful to solve several problems of robotics, such as loop closures detection for \gls*{slam}. Our research is therefore useful to assess whether the solutions currently operating in structured environments can also be used successfully for more complex environments. The Husky A200 robotic platform was used to acquired point clouds using the SICK and Velodyne \gls*{lidar}s in the two desired type of environments. An outdoor area containing several man-made structures, including buildings, was used as our structured environment and a forest area was used as our unstructured environment. A path forming a loop has been set in each area and has been covered twice to produce examples of recognizable places.

After summarizing the concepts of feature keypoints and descriptors, we explained how to convert point clouds into range images and use this data representation to extract NARF features from our scans. As we mentioned, these features have the advantage to consider only edges produced by objects boundary, as opposed to edges caused by occlusion. To finalize our review of fundamental concepts, we discussed some existing methods for comparing scans, which are used for place recognition. Thereafter, we described the place recognition algorithm we choose for our comparative analysis, which was presented in \citep{Steder2011b}. This algorithm use NARF features with a technique combining \gls*{bow} and features matching for scoring two input scans, according on how they are likely to originate from the same place. 

Before beginning the comparative analysis, we explain the processing performed on our data for results presentation. The physical distance between two scans was used to determine whether or not they are considered to be in the same place. This value was obtained from the odometry corrected using \gls*{icp}. We expected to see an inverse relationship between this distance and the score of the place recognition algorithm, which turn out to be true for all our datasets. The results were also presented using discrete labels to be more faithful to practical uses, in which two scans either originate or not from the same place. Using these labels, it was possible to identify false positives, which have to be avoided when the place recognition algorithm is used for loop closures detection. Furthermore, this discretization allowed us, for different score thresholds, to compute the recall as function of the place recognition range (i.e. maximum distance between two scans to be considered as originating from the same place).

Finally, we conducted our comparative analysis. The first important finding is that the unstructured dataset produced some outliers regarding the relation between the place recognition range and the algorithm output score, which was not the case for the structured dataset. These outliers greatly reduces the algorithm's performance when false positives have to be avoided. Another important observation is that the scores remain high enough to significantly distinguish the scans acquired in the same place compared to those not acquired in the same place by up to about 10 meters higher for the structured environment. We also compared the results for the SICK and Velodyne \gls*{lidar}s in the unstructured environment. Results for those sensors were relatively similar, but data acquired with the Velodyne produced scores more concentrated near the minimum possible values, which increases the sensitivity to disturbances.

