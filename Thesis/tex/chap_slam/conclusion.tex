\section{Conclusion}
\label{sec:chap_slam_conclu}

This chapter focused on the impact of the level of structure (man-made vs. natural) of an environment on the performance of a \gls*{lidar}-based place recognition algorithm. As explained, these algorithms are key to solving several important problems of mobile robotics, such as loop closures detection for \gls*{slam}. Our research is therefore useful to assess whether an existing solution based on NARF, currently operating in structured environments, can also be used successfully for more complex, unstructured environments. Our experiments were based on real datasets collected with a Husky A200 robotic platform, using either the SICK or the Velodyne \gls*{lidar} as the main sensing device in the two desired type of environments. An outdoor area containing several man-made structures, including buildings, was used as our structured environment and a forest area was used as our unstructured environment. Paths forming a loop were followed by the robot twice in each environment to produce examples of recognizable places.

After summarizing the concepts of feature keypoints and descriptors, we explained how to convert point clouds into range images and use this data representation to extract a specific type of feature called NARF. As mentioned, these features have the advantage to consider only edges produced by objects boundary, as opposed to edges caused by occlusion, making them a sensible choice for place recognition in complex environments. Thereafter, we described the place recognition algorithm we choose for our comparative analysis, which was presented in \citep{Steder2011b}. This algorithm uses NARF features with a technique combining \gls*{bow} and features matching for scoring two input scans, according on how they are likely to originate from the same place. 

The physical distance between two scans was used to determine whether or not they are considered to be in the same place. This value was obtained from the odometry corrected using \gls*{icp}. We expected to see a generally decreasing relationship between the score of the place recognition algorithm and the distance between the input scans, which turn out to be true for all our datasets. The results were also presented using discrete labels to be more faithful to practical uses, in which two scans either originate or not from the same place. Using these labels, it was possible to identify false positives, which must be avoided when the place recognition algorithm is used for loop closures detection. Furthermore, this discretization allowed us, for different score thresholds, to compute the recall as function of the place recognition range (i.e. maximum distance between two scans to be considered as originating from the same place).

The first important finding of our comparative analysis was that the unstructured dataset produced some outliers regarding the relation between the place recognition range and the algorithm output score, which was not the case for the structured dataset. These outliers greatly reduces the algorithm's performance when false positives have to be avoided.  Another important observation was that \todo{Finale pas claire... The scores drop significantly faster with distance in the unstructured env. when compared to the structured env., limitant les performances de reconnaissance robuste a un rayon infereur a 10 metres en foret} the scores remained high enough to significantly distinguish the scans acquired in the same place compared to those not acquired in the same place by up to about 10 meters higher for the structured environment. We also compared the results for the SICK and Velodyne \gls*{lidar}s in the unstructured environment. Results for those sensors were relatively similar, but data acquired with the Velodyne \todo{fin, ne rend pas bien le message} produced scores more concentrated near the minimum possible values, which increases the sensitivity to disturbances.

